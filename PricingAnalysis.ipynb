{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "PricingAnalysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KasiBaskerLaxmanan/pyalgotrading/blob/master/PricingAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK6U4zE7uGkc",
        "colab_type": "text"
      },
      "source": [
        "<font color = red>Pricing Analysis Using Python</font>\n",
        "=======\n",
        "<br>\n",
        "    <center><img src=\"http://dataanalyticscorp.com/wp-content/uploads/2018/03/logo.png\"></center>\n",
        "<br>\n",
        "Taught by: \n",
        "\n",
        "* Walter R. Paczkowski, Ph.D. \n",
        "\n",
        "    * My Affliations: [Data Analytics Corp.](http://www.dataanalyticscorp.com/) and [Rutgers University](https://economics.rutgers.edu/people/teaching-personnel)\n",
        "    * [Email Me With Questions](mailto:walt@dataanalyticscorp.com)\n",
        "    * [Learn About Me](http://www.dataanalyticscorp.com/)\n",
        "    * [See My LinkedIn Profile](https://www.linkedin.com/in/walter-paczkowski-a17a1511/)\n",
        "    * [My Books](https://www.amazon.com/-/e/B084KK4SF5?ref_=pe_1724030_132998070)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9gZ4oV6uGkg",
        "colab_type": "text"
      },
      "source": [
        "## Slide Set-up\n",
        "\n",
        "This code sets up the presentation slides."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR0LwnBKuGkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## slide code\n",
        "##\n",
        "from IPython.display import Image\n",
        "def slide(what):\n",
        "    display( Image( \"../Slides/PA_Page_\" + what + \".png\", width = 50, height = 50, retina = True ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCiUyueauGkv",
        "colab_type": "text"
      },
      "source": [
        "## Contents\n",
        "\n",
        "1. [**_Helpful Background_**](#Helpful-Background)\n",
        "    1. [About this Notebook](#About-this-Notebook)\n",
        "    2. [Helpful Online Tutorials](#Helpful-Online-Tutorials)\n",
        "    3. [Helpful/Must-Read Books](#Helpful/Must-Read-Books)\n",
        "2. [**_Lesson 0: Preliminary Stuff_**](#Lesson-0:-Preliminary-Stuff)\n",
        "    1. [Load Python Packages](#Load-Python-Packages)\n",
        "    2. [Set Data Path](#Set-Data-Path)\n",
        "3. [**_Lesson I: Introduction_**](#Lesson-I:-Introduction) \n",
        "4. [**_Lesson II: Survey Approach to Pricing_**](#Lesson-II:-Survey-Approach-to-Pricing)\n",
        "    1. [The Pricing Problem for Conjoint](#The-Pricing-Problem-for-Conjoint)\n",
        "    2. [Analysis Steps for Conjoint](#Analysis-Steps-for-Conjoint)\n",
        "    3. [The Setting for Conjoint](#The-Setting-for-Conjoint)\n",
        "    4. [Conjoint Design Matrix Generation](#Conjoint-Design-Matrix-Generation)\n",
        "    5. [Sample Card for Fielding Study](#Sample-Card-for-Fielding-Study)\n",
        "    6. [Import the Responses](#Import-the-Responses)\n",
        "    7. [Concatenate the Design Matrix and Responses](#Concatenate-the-Design-Matrix-and-Responses)\n",
        "    8. [Estimate Part-worth Utilities](#Estimate-Part-worth-Utilities)\n",
        "    9. [Calculate Attribute Importances](#Calculate-Attribute-Importances)\n",
        "    10. [Calculate the Price Elasticities](#Calculate-the-Price-Elasticities)\n",
        "\n",
        "5. [**_Lesson III: Transactions Data Approach to Pricing_**](#Lesson-III:-Transactions-Data-Approach-to-Pricing)\n",
        "    1. [The Pricing Problem for Transactions](#The-Pricing-Problem-for-Transactions)\n",
        "    2. [Import the Stores Data](#Import-the-Stores-Data)\n",
        "    3. [Check the Data](#Check-the-Data)\n",
        "    4. [Model Estimation I: Pooled Model](#Model-Estimation-I:-Pooled-Model)\n",
        "        1. [Calculate the Price Elasticities: I](#Calculate-the-Price-Elasticities:-I)\n",
        "    5. [Model Estimation II: Dummy Model](#Model-Estimation-II:-Dummy-Variable-Model)\n",
        "        1. [Calculate the Price Elasticities: II](#Calculate-the-Price-Elasticities:-II)\n",
        "    6. [Model Estimation III: Multilevel Model](#Model-Estimation-III:-Multilevel-Model)\n",
        "6. [**_Summary and Wrap-Up_**](#Summary-and-Wrap-Up)\n",
        "7. [**_Contact Information_**](#Contact-Information)\n",
        "8. [**_Appendix: Extra Material_**](#Appendix:-Extra-Material)\n",
        "    1. [Conjoint Analysis](#Conjoint-Analysis) \n",
        "        1. [Display Attribute Importances](#Display-Attribute-Importances)\n",
        "        2. [Calculate Willingness-to-Pay (*WTP*)](#Calculate-Willingness-to-Pay)\n",
        "    2. [Transactions Analysis](#Transactions-Analysis)\n",
        "        1. [Check Distributions](#Check-Distributions)\n",
        "        2. [Sales and Price Relationship](#Sales-and-Price-Relationship)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0llOehUuGkx",
        "colab_type": "text"
      },
      "source": [
        "## Helpful Background\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "\n",
        "### About this Notebook\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "This notebook accompanies the PDF presentation **_Pricing Analysis Using Python_** by Walter R. Paczkowski, Ph.D. (2020).  There is more content and commentary in this notebook than in the presentation deck.  Nonetheless, the two complement each other and so should be studied together.  Every effort has been made to use the same key slide titles in the presentation deck and this notebook to help your learning.\n",
        "\n",
        "### Helpful Online Tutorials\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "* <a href=\"http://docs.python.org/2/tutorial/\" target=\"_parent\">Python Tutorial</a>\n",
        "\n",
        "* <a href=\"https://pandas.pydata.org/pandas-docs/stable/getting_started/tutorials.html\" target=\"_parent\">Pandas Tutorial</a>\n",
        "\n",
        "* <a href=\"https://seaborn.pydata.org/tutorial.html\" target=\"_parent\">Seaborn Tutorial</a>\n",
        "\n",
        "* <a href=\"https://www.statsmodels.org/stable/index.html\" target=\"_parent\">Statsmodels Tutorial</a>\n",
        "\n",
        "\n",
        "### Helpful/Must-Read Books\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "* <a href=\"https://www.routledge.com/Pricing-Analytics-Models-and-Advanced-Quantitative-Techniques-for-Product/Paczkowski/p/book/9781138623934\" target=\"_parent\">Main Pricing go-to book: </a> *Pricing Analytics\n",
        "Models and Advanced Quantitative Techniques for Product Pricing* (1st Edition) by Walter R. Paczkowski.\n",
        "\n",
        "* <a href=\"https://www.amazon.com/gp/product/1491957662/ref=as_li_tl?ie=UTF8&tag=quantpytho-20&camp=1789&creative=9325&linkCode=as2&creativeASIN=1491957662&linkId=8c3bf87b221dbcd8f541f0db20d4da83\" target=\"_parent\">Main Pandas go-to book: </a> *Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython* (2nd Edition) by Wes McKinney."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGsoLiHVuGky",
        "colab_type": "text"
      },
      "source": [
        "## Lesson 0: Preliminary Stuff\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "### Load Python Packages\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "You have to load a Python package before you can use it.  Loading is done using an *import* command.  An alias is assigned when you import the package.  I recommend loading all the packages at once at the beginning of your notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkayHtA2uGk0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## ===> Data Management <===\n",
        "##\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "##\n",
        "## ===> Visualization <===\n",
        "##\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "##\n",
        "## ===> Modeling <===\n",
        "##\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf \n",
        "from statsmodels.iolib.summary2 import summary_col\n",
        "##\n",
        "from patsy.contrasts import Sum\n",
        "##\n",
        "## ===> Hypothesis Testing <===\n",
        "##\n",
        "from scipy.stats import skewtest\n",
        "##\n",
        "## ===> Experimental Design <===\n",
        "##\n",
        "import random\n",
        "random.seed( 42 )\n",
        "import pyDOE2\n",
        "##\n",
        "## ===> Preprocessing <===\n",
        "##\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blWow3SpuGk-",
        "colab_type": "text"
      },
      "source": [
        "**_Code Explanation_**\n",
        "\n",
        "This code block loads the necessary Python packages for this course.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP8aDNwAuGlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Run if needed to install pyDOE2.\n",
        "## Removing the ## at the beginning of the last line.\n",
        "##\n",
        "##!pip install -q pyDOE2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxKzo2tduGlJ",
        "colab_type": "text"
      },
      "source": [
        "### Set Defaults"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKchtN-buGlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Default formats\n",
        "##\n",
        "font_title = 20\n",
        "format = '{:0.1%}'\n",
        "format_dollar = '${:,.2f}'\n",
        "p_value = '{:0.4f}'\n",
        "##\n",
        "## DataFrame styles\n",
        "##\n",
        "tbl_styles = [ {\n",
        "    'selector': 'caption',\n",
        "    'props': [\n",
        "        ('color', 'red'),\n",
        "        ('font-size', '18px')\n",
        "    ] } ]\n",
        "##\n",
        "## Misc functions for graphs\n",
        "##\n",
        "def footer():\n",
        "    ax.annotate( base, ( 0, 0 ), ( 0, -0.3 ), xycoords = 'axes fraction' )\n",
        "def tick_labels( tick ):\n",
        "    if tick == 'y':\n",
        "        vals = ax.get_yticks()\n",
        "        ax.set_yticklabels( format.format( x ) for x in vals )\n",
        "    else:\n",
        "        vals = ax.get_xticks()\n",
        "        ax.set_xticklabels( format.format( x ) for x in vals )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qELeeL2quGlS",
        "colab_type": "text"
      },
      "source": [
        "### Set Data Path\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "It is best practice to define paths in one location.  This makes error finding and changes easier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIu2n9tZuGlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Set data path.\n",
        "##\n",
        "path = '../Data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLQznQzRuGle",
        "colab_type": "text"
      },
      "source": [
        "## Lesson I: Introduction\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "A *pricing strategy* has two parts:\n",
        "\n",
        "1. **Price Structure**: How prices are delivered -- uniformly or discriminatorily.\n",
        "\n",
        "    > Example: A high price at the beginning of a fashion season and a low price at the end to target consumers based on their price sensitivities or *elasticities*.\n",
        "\n",
        "2. **Price Level**: The price point actually charged.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujy3lLr-uGlg",
        "colab_type": "text"
      },
      "source": [
        "Just as important as the price level is the price *effect*.  All too often, managers just think of \"stimulating demand\" by lowering the price.  This is too narrow and simplistic -- and dangerous.\n",
        "\n",
        "**Think More Broadly**\n",
        "\n",
        "> *What is the effect of a different price structure and/or level on a key business metric (*KBM*)* such as:\n",
        "> 1. Revenue?\n",
        "> 2. Bid win?\n",
        "> 3. Contribution?\n",
        "> 4. Customer acquisition?\n",
        "> 5. Customer retention?\n",
        "> 6. Market share?\n",
        "\n",
        "This is where *price elasticities* become important."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRjj0Z4BuGlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slide( '08' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFFB9WL_uGls",
        "colab_type": "text"
      },
      "source": [
        "There are two approaches to developing elasticities:\n",
        "\n",
        "1. Survey-based\n",
        "\n",
        "    1. Conjoint\n",
        "\t2. Discrete choice\n",
        "\t3. Granger-Gabor\n",
        "\t4. van Westendorp Price Sensitivity Meter\n",
        "\n",
        "2. Transactions-based\n",
        "\n",
        "    1. Regression modeling\n",
        "\n",
        "I will illustrate both approaches with:\n",
        "\n",
        "- Conjoint analysis\n",
        "- Transactions regression analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X89kV74suGlt",
        "colab_type": "text"
      },
      "source": [
        "## Lesson II: Survey Approach to Pricing\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "I will illustrate a survey approach to pricing using a Conjoint study.  This is just one of several survey approaches.  Others are:\n",
        "\n",
        "> 1. Discrete Choice\n",
        "> 2. MaxDiff\n",
        "> 3. Granger-Gabor\n",
        "> 4. Von Westendorf Price Sensitivity Meter\n",
        "\n",
        "The Conjoint approach is used to illustrate what can be done using Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37DjyuJ6uGlv",
        "colab_type": "text"
      },
      "source": [
        "### The Pricing Problem for Conjoint\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "A watch manufacturer wants to develop and price a new men's fitness watch.  \tShe can only market one product.  There are four *features*, *factors*, or *attributes*} that define the watch:\n",
        "\n",
        "> - **Price**: \\$149.99, \\$179.99, \\$229.99.\n",
        "> - **Compatibility**: Android, iOS, Windows.\n",
        "> -\t**Measure**: Calories, Distance, Heart Rate.\n",
        "> - **Rain/Splash Proof**: Yes, No.\n",
        "\n",
        "There are 54 possible watches based on these attributes.\n",
        "\n",
        "**Problem**\n",
        "\n",
        "> <font color = red>***What is the best watch to sell and at what price?***</font>\n",
        "\n",
        "A model is needed to answer this question.  This is a conjoint model.  A conjoint model is one member of a family of *choice models*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGnAqMnBuGlx",
        "colab_type": "text"
      },
      "source": [
        "### Analysis Steps for Conjoint\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "1. Identify the product's attributes and their levels.\n",
        "2. Create a design matrix of the attributes and their levels.\n",
        "3. Field the study and collect responses.\n",
        "4. Create a data matrix for estimation and estimate a model.\n",
        "5. Analyze the results:\n",
        "    1. Attribute importances.\n",
        "    2. Elasticities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vfK1G-WuGlz",
        "colab_type": "text"
      },
      "source": [
        "### The Setting for Conjoint\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "> **Factors and levels for a new watch**:\n",
        "\n",
        "- Compatibility: Android, iOS, Windows\n",
        "- Measure: Calories, Distance, Heart Rate\n",
        "- Price: \\\\$149.99, \\\\$179.99, \\\\$229.99 \n",
        "- Rain/Splash Proof: No, Yes\n",
        "\n",
        "> **Total number of combinations**:\n",
        "\n",
        "$Combinations = 3 \\times 3 \\times 3 \\times 2 = 54$\n",
        "\n",
        "> **Parameters needed for this problem**:\n",
        "\n",
        "| Attributes          | Number of Levels | Parameters Needed |\n",
        "|---------------------|------------------|-------------------|\n",
        "| Compatibility       | 3                | 2                 |\n",
        "| Measure             | 3                | 2                 |\n",
        "| Price\t\t          | 3                | 2                 |\n",
        "| Rain/Splash Proof   | 2                | 1                 |\n",
        "| Sub Total           | 11               | 7                 |\n",
        "| Constant            |                  | 1                 |\n",
        "| Minimum Runs Needed |                  | 8                 |\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3_3lVEYuGl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Create a design dictionary for future use\n",
        "##\n",
        "att = [ 'Compatibility', 'Measure', 'Price', 'Rain/Splash Proof' ]\n",
        "dt_att = { 'compat':'Compatible', 'measure':'Measure', 'price':'Price', 'rain':'Rain' }\n",
        "dt = {\n",
        "    'compat': { 0:'Android', 1:'iOS', 2:'Windows' },\n",
        "    'measure': { 0:'Calories', 1:'Heart Rate', 2:'Distance' },\n",
        "    'price': { 0:'$149.99', 1:'$179.99', 2:'$229.99' },    \n",
        "    'rain': { 0:'No', 1:'Yes' }\n",
        "    }\n",
        "##\n",
        "## Retrieve number of levels of each attribute\n",
        "##\n",
        "levels = [ len( list( value ) ) for value in dt.values() ]\n",
        "##\n",
        "## Print summary\n",
        "##\n",
        "print( 'Design Summary:\\n' )\n",
        "print( '\\nAttributes:\\n{}'.format( list( dt.keys() ) ) )\n",
        "print( '\\nLevels:\\n{}'.format( levels ) )\n",
        "print( '\\nAttribute mappings:\\n{}'.format( dt_att ) )\n",
        "print( '\\nDictionary of attributes:\\n{}'.format( dt ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-L76NE2uGl8",
        "colab_type": "text"
      },
      "source": [
        "### Conjoint Design Matrix Generation\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "A *design matrix* must be generated.  Use the ***pyDOE2*** package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmBfKDEmuGl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Generate the conjoint design with 18 ( = 54/3 ) runs\n",
        "##\n",
        "fraction = 3                             ## One-third fraction\n",
        "design = pyDOE2.gsd( levels, fraction )  ## Reduce the number of experiment to approximately a third.\n",
        "print( 'Design with: ' + str( design.shape[ 0 ] ) + ' rows and ' + str( design.shape[ 1 ] ) + ' columns' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "lOSlNlMwuGmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Create DataFrame for the design matrix\n",
        "##\n",
        "## ===> Step 1: Create column names using list \n",
        "##              comprehension on the design dictionary\n",
        "##\n",
        "colnames =  [ key for key in dt.keys() ]\n",
        "##\n",
        "## ===> Step 2: Create DataFrame\n",
        "##\n",
        "df_design = pd.DataFrame( design, columns = colnames )\n",
        "df_design.head().style.set_caption( 'Conjoint Matrix' ).\\\n",
        "set_table_styles( tbl_styles ).\\\n",
        "hide_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBIckX-9uGmF",
        "colab_type": "text"
      },
      "source": [
        "### Sample Card for Fielding Study\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "This is what you might show consumers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tQwEgOSuGmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## \n",
        "## Recode design matrix with labels\n",
        "##\n",
        "n = df_design.shape[ 1 ]  ## number of columns\n",
        "for i in range( n ):\n",
        "    x = colnames[ i ]\n",
        "    df_design[ x ] = df_design[ x ].replace( dt[ x ] )\n",
        "##\n",
        "df_design.head().style.set_caption( 'Recoded Design Matrix' ).\\\n",
        "set_table_styles( tbl_styles ).\\\n",
        "hide_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-3JTSnLuGmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Sample card shown to a consumer\n",
        "##\n",
        "lst = df_design.query( 'index == 0' ).values.tolist()[ 0 ]\n",
        "n = len( lst )\n",
        "msg = (\"On a scale from 0 to 10, where '0' means you definitely will not buy this watch and '10' means{sep}\"\n",
        "       \"you definitely will buy it, you may use any number between 0 and 10, please indicate your{sep}\"\n",
        "       \"likelihood of buying the following watch.\").format( sep = '\\n' ) \n",
        "print( '-'*95 )\n",
        "print( msg )\n",
        "for i in range( n ):\n",
        "    print( '\\n\\t' + att[ i ] + ': {}'.format( lst[ i ] ) )\n",
        "print( '-'*95 )\n",
        "print( '\\t0\\t1\\t2\\t3\\t4\\t5\\t6\\t7\\t8\\t9\\t10')\n",
        "print( '-'*95 )\n",
        "print( \"   Will Not Buy\\t\\t\\t\\t\\t\\t\\t\\t\\t     Will Buy\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED2oBvVHuGmT",
        "colab_type": "text"
      },
      "source": [
        "### Import the Responses\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "The collected data are in a *CSV* file.  An *SPSS* file is also possible, especially if an online survey tool is used.  For my example, the data are in a *CSV* file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lkyiuDfuGmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Import responses from CSV file\n",
        "##\n",
        "df_responses = pd.read_csv( '../Data/responses.csv' )\n",
        "df_responses.head( ).style.set_caption( 'Responses with ID and Set Indicators' ).\\\n",
        "format( { 'response':'{:.0f}' } ).\\\n",
        "set_table_styles( tbl_styles ).\\\n",
        "hide_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMGqpgFfuGma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Check response DataFrame counts\n",
        "##\n",
        "print( 'Number of rows: {rows}\\nNumber of columns: {cols}'.format( \n",
        "        rows = df_responses.shape[ 0 ], cols = df_responses.shape[ 1 ] ) )\n",
        "##\n",
        "## Record the number of respondents\n",
        "##\n",
        "n_respondents = df_responses.ID.nunique()\n",
        "print( '\\nNumber of unique respondents: {}'.format( n_respondents ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK3HWE_VuGme",
        "colab_type": "text"
      },
      "source": [
        "### Concatenate the Design Matrix and Responses\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "The design matrix and the responses have to be joined or merged."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9V8dgBnuGmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Replicate the design matrix to match the number of respondents\n",
        "##\n",
        "n_respondents = df_responses.ID.nunique()\n",
        "for i in range( n_respondents ):\n",
        "    if i == 0:\n",
        "        tmp = df_design\n",
        "    else:\n",
        "        tmp = pd.concat( [ tmp, df_design], ignore_index = True ) \n",
        "##\n",
        "## Attach ID and Set Number to the replicated design matrix\n",
        "##\n",
        "## Set some parameters\n",
        "##\n",
        "n = n_respondents + 1\n",
        "runs = df_design.shape[ 0 ]\n",
        "##\n",
        "tmp[ 'ID' ] = [ x for x in range( 1, n ) for i in range( runs ) ] \n",
        "tmp[ 'set' ] = [item for x in [ range( 1, runs + 1 ) for  i in range( 1, n ) ] for item in x ]\n",
        "##\n",
        "## Remove dollar sign from price and set type to float\n",
        "##\n",
        "tmp.price = tmp.price.str.replace( '$', '' ).astype( float )\n",
        "##\n",
        "## Merge the design and response DataFrames on ID and Set\n",
        "##\n",
        "df_conjoint =  pd.merge( df_responses, tmp, on = [ 'ID', 'set' ] )\n",
        "df_conjoint.head().style.set_caption( 'Merged Conjoint DataFrame' ).\\\n",
        "format( { 'response':'{:.0f}', 'price':'{:.2f}' } ).\\\n",
        "set_table_styles( tbl_styles ).\\\n",
        "hide_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3E1MVq5uGmi",
        "colab_type": "text"
      },
      "source": [
        "### Estimate Part-worth Utilities\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "\n",
        "The model is for the total preference or *total utility* for combinations of attributes of a product concept.  Total utility is composed of pieces called *part-worths*, each part-worth measuring the contribution of each attribute's level.\t\n",
        "\n",
        "The goal is to estimate these part-worth utilities enabling the calculation of total utility for each of the 54 watches.\n",
        "\n",
        "Ordinary least squares (*OLS*) regression can be used for estimation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "FprdNoSZuGmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Follow four steps to estimate a model\n",
        "##\n",
        "## ===> Step 1: Specify the model formula <===\n",
        "##\n",
        "## The Sum() function results in an effects coding \n",
        "## for the categorical variable\n",
        "##\n",
        "formula = \"np.log( response ) ~ np.log(price) + \\\n",
        "C(compat, Sum( 'Windows' ) ) + \\\n",
        "C(measure, Sum( 'Heart Rate' ) ) + \\\n",
        "C(rain, Sum( 'No' ) )\"\n",
        "##\n",
        "## ===> Step 2: Instantiate the model <===\n",
        "##\n",
        "mod = smf.ols( formula, data = df_conjoint )\n",
        "##\n",
        "## ===> Step 3: Fit the model <===\n",
        "##\n",
        "reg01 = mod.fit()\n",
        "##\n",
        "## ===> Step 4: Summarize the model <===\n",
        "##\n",
        "print(reg01.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Gypz2rfuGmp",
        "colab_type": "text"
      },
      "source": [
        "**Code Explanation**\n",
        "\n",
        "The *formula* step uses the \"C\" function to indicate that the categorical variable, *compat*, must be encoded.  The *Sum( 'Windows' )*  argument says to use *effects coding* so that the sum of the estimated coefficients for *compat* levels add to zero (including the omitted level).  The omitted level is the base which is specified as *Windows*.\n",
        "<br><br>\n",
        "The Numpy *log* function is used to take the (natural) log of price.\n",
        "\n",
        "**Interpretation**\n",
        "\n",
        "The estimated coefficient for the log-Price is the price elasticity.  This will used below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqvUnZ44uGmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Retrieve the part-worths\n",
        "##\n",
        "x = reg01.params[ 1:7 ]\n",
        "part_worths = [ x[ i ] for i in range( len( x ) ) ]\n",
        "##\n",
        "## Put into a DataFrame with labels\n",
        "##\n",
        "df_pw = pd.DataFrame( part_worths, columns = [ 'Part-Worth' ], index = x.index )\n",
        "df_pw.style.set_caption( 'Estimated Part-Worths' ).\\\n",
        "set_table_styles( tbl_styles ).\\\n",
        "format( '{:.4f}' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqbm_mx_uGmt",
        "colab_type": "text"
      },
      "source": [
        "## Calculate Attribute Importances\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "Calculate attribute importances.  The importance of an attribute is the range of the attribute divided by the total range of all attributes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "2T9Vhon2uGmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Retrieve and clean part-worth index for attributes\n",
        "##\n",
        "lst_att = [ i.split( 'C(' )[ 1 ].split( ',' )[ 0 ] for i in df_pw.index[ 0:-1 ] ]\n",
        "lst_level = [ i.split( 'S.' )[ 1 ].split( ']' )[ 0 ] for i in df_pw.index[ 0:-1 ] ]\n",
        "lst_att.append( 'Price' )\n",
        "lst_level.append( 'log_Price' )\n",
        "##\n",
        "## Add attribute list to part-wroth DataFrame\n",
        "##\n",
        "df_pw[ 'att' ] = lst_att\n",
        "df_pw[ 'level' ] = lst_level\n",
        "##\n",
        "## Calculate dropped values\n",
        "##\n",
        "grp = pd.DataFrame( df_pw.groupby( 'att' )[ 'Part-Worth' ].sum()*( -1 ) )\n",
        "grp.reset_index( inplace = True )\n",
        "##\n",
        "## Add dropped levels to base\n",
        "##\n",
        "data = pd.concat( [ df_pw, grp ], axis = 0, sort = False, ignore_index = True )\n",
        "data.replace( { 'att':dt_att }, inplace = True )\n",
        "data.sort_values( by = [ 'att', 'level' ], inplace = True )\n",
        "##\n",
        "## Calculate importances\n",
        "##\n",
        "grp = data.groupby( 'att' ).apply( lambda x: x[ 'Part-Worth' ].max() - x[ 'Part-Worth' ].min() )\n",
        "df_importances = pd.DataFrame( grp/grp.sum(), columns = [ 'Importance' ] )\n",
        "df_importances.rename_axis( 'Attribute', inplace = True )\n",
        "df_importances.sort_values( by = [ 'Importance' ], ascending = False, inplace = True )\n",
        "##\n",
        "df_importances.style.set_caption( 'Attribute Importances' ).\\\n",
        "set_table_styles( tbl_styles ).\\\n",
        "bar( align = 'mid' ).format( '{:.1%}' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p6pqpRAuGmy",
        "colab_type": "text"
      },
      "source": [
        "**Code Explanation**\n",
        "\n",
        "The base level of each attributed can be retrieved as the negative of the sum of the etsimated coefficients for an attribute.  This is an advantage of effects coding.\n",
        "\n",
        "**Interpretation**\n",
        "\n",
        "Price is the most important attribute for the watches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnY6nI06uGmy",
        "colab_type": "text"
      },
      "source": [
        "## Calculate the Price Elasticities\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "There are two elasticities: price and revenue.  The revenue elasticity equals $1 + \\eta$ where $\\eta$ is the price elasticity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "ZwFP2E9muGmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Retrieve estimated price parameter\n",
        "##\n",
        "eta = df_pw.query( 'att == \"Price\"' )[ 'Part-Worth' ][ 0 ]\n",
        "##\n",
        "## The revenue elasticity is 1 + price elasticity\n",
        "##\n",
        "eta_rev = 1 + eta\n",
        "##\n",
        "## Put in DataFrame for display\n",
        "##\n",
        "df_elas = pd.DataFrame( [ eta, eta_rev ], columns = [ 'Elasticities'], \n",
        "    index = [ 'Price Elasticity', 'Revenue Elasticity' ] )\n",
        "df_elas.style.set_caption( 'Elasticity Summary').\\\n",
        "set_table_styles( tbl_styles ).\\\n",
        "format( '{:.1f}' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHz6fShruGm2",
        "colab_type": "text"
      },
      "source": [
        "**Code Explanation**\n",
        "\n",
        "The Pandas *query* method was used to subset the data for the Price attribute.\n",
        "\n",
        "**Interpretation**\n",
        "\n",
        "Watches are highly elastic.  A 1% increase in price will result in a 1.3% decrease in take.  Revenue will fall 0.3%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Vl1nWYCuGm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slide( '17' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbS66KpzuGm6",
        "colab_type": "text"
      },
      "source": [
        "## Lesson III: Transactions Data Approach to Pricing\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "Price elasticities and price points are often determined using transactions data.  The data could be in a data warehouse or data mart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4T-u5QpuGm7",
        "colab_type": "text"
      },
      "source": [
        "### The Pricing Problem for Transactions\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "Fictional data on a retail chain in New England states.\n",
        "\n",
        "- One consumer product\n",
        "- Six stores\n",
        "  - 3 Urban (Small)\n",
        "  - 3 Suburban (Large)\n",
        "- 600 consumers\n",
        "  - Each consumer's purchases and prices averaged to one annual number so $n = 600$.\n",
        "- Consumer data:\n",
        "  - Average price paid\n",
        "  - Household income\n",
        "  - Average purchase size\n",
        "\n",
        "#### **Pricing Conjecture**\n",
        "\n",
        "The store location impacts pricing: *Urban stores are more elastic because of more intense competition, so a lower price point should be used*.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CTKd5S0uGm8",
        "colab_type": "text"
      },
      "source": [
        "### Import the Stores Data\n",
        "\n",
        "[Back to Contents](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Fe76oC0YuGm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv( path + 'stores.csv' )\n",
        "##\n",
        "## Insert underscore in column name if it\n",
        "## has an internal whitespace.  This will make\n",
        "## using names easier.\n",
        "##\n",
        "cols = df.columns\n",
        "cols = [ x.replace( ' ', '_' ) for x in cols ]\n",
        "df.columns = cols\n",
        "df.head().style.set_caption( 'Stores Transactions Data' ).\\\n",
        "set_table_styles( tbl_styles ).\\\n",
        "hide_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9r9A4u-uGnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Check DataFrame counts\n",
        "##\n",
        "print( 'Number of rows: {rows}\\nNumber of columns: {cols}'.format( \n",
        "        rows = df.shape[ 0 ], cols = df.shape[ 1 ] ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTJ4ScSQuGnE",
        "colab_type": "text"
      },
      "source": [
        "### Check the Data\n",
        "\n",
        "[Back to Contents](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "AUqnxZWLuGnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Check distribution of sales\n",
        "##\n",
        "base = 'Base: All stores; n = ' + str( df.shape[ 0 ] )\n",
        "ax = sns.distplot( df.quantity )\n",
        "ax.set_title( 'Distribution of Store Sales', fontsize = font_title )\n",
        "ax.set( xlabel = 'Quantity', ylabel = 'Density' )\n",
        "footer();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7LOBOYIuGnH",
        "colab_type": "text"
      },
      "source": [
        "**Interpretation**\n",
        "\n",
        "There seems to be some slight right skewness in the sales data.  Right skewness is typical for sales (and price) data.  You can test the skewness against the Normal Distribution.  The skewness for the Normal is zero because the distribution is symmetric about the mean.  So the Null Hypothesis for the test is that the skewness of the sales data is the same as that for the Normal Distribution: zero.  A Z-test is done. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYkT_goXuGnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Test skewness\n",
        "##\n",
        "sk = skewtest( df.quantity )\n",
        "print( 'Z-score: {z}\\np-Value: {p}'.format( z = round( sk[ 0 ], 3 ), p = round( sk[ 1 ], 4 ) ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvancELtuGnL",
        "colab_type": "text"
      },
      "source": [
        "**Interpretation**\n",
        "\n",
        "A positive Z-score indicates right-skewness which agrees with what we observed.  The p-value is less than 0.05 so we reject the Null Hypthesis of zero skewness.  \n",
        "<br>\n",
        "How do we fix the skewness?  Taking the natural log of the data is the usualy fix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2hkety1uGnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Distribution based on natural log\n",
        "##\n",
        "base = 'Base: All stores; n = ' + str( df.shape[ 0 ] )\n",
        "ax = sns.distplot( df.log_Quantity )\n",
        "ax.set_title( 'Distribution of Store Sales', fontsize = font_title )\n",
        "ax.set( xlabel = 'Quantity', ylabel = 'Density' )\n",
        "footer();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmKjIY3yuGnO",
        "colab_type": "text"
      },
      "source": [
        "### Types of Models\n",
        "  \n",
        "There are three types of models we can consider:\n",
        "\n",
        "> - **Pooled**:Use all the data in one model.\n",
        "> - **Dummy Variable**: Segment the data by store size with dummies.\n",
        "> - **Multilevel**: Account for the hierarchical structure of stores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6r6pbAwuGnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slide( '24' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pScSkcRPuGnS",
        "colab_type": "text"
      },
      "source": [
        "### Model Estimation I: Pooled Model\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "Pool all the data into one model without regard for store location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "xxf2yaDDuGnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## \n",
        "## OLS\n",
        "##\n",
        "## There are four steps for estimatng a model:\n",
        "##\n",
        "##   1. define a formula (i.e., the specific model to estimate)\n",
        "##   2. instantiate the model (i.e., specify it)\n",
        "##   3. fit the model\n",
        "##   4. summarize the fitted model\n",
        "##\n",
        "## ===> Step 1: Define a formula <===\n",
        "##\n",
        "## The formula uses a “~” to separate the left-hand side from the right-hand side\n",
        "## of a model and a “+” to add columns to the right-hand side.  A “-” sign (not \n",
        "## used here) can be used to remove columns from the right-hand side (e.g.,\n",
        "## remove or omit the constant term which is always included by default). \n",
        "##\n",
        "formula = 'log_Quantity ~ log_Price + log_Income'\n",
        "##\n",
        "## ===> Step 2: Instantiate the OLS model <===\n",
        "##\n",
        "mod = smf.ols( formula, data = df )\n",
        "##\n",
        "## ===> Step 3: Fit the instantiated model <===\n",
        "##      Recommendation: number your fitted models\n",
        "##\n",
        "reg01 = mod.fit() \n",
        "##\n",
        "## ===> Step 4: Summarize the fitted model <===\n",
        "##\n",
        "print( reg01.summary() )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRiqCbu4uGnU",
        "colab_type": "text"
      },
      "source": [
        "#### Calculate the Price Elasticities: I\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "Since this is a log-log model, the price elasticity is just the estimated parameter for log-Price."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlL8hJP2uGnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Retrieve the coefficient for log-Price as the elasticity\n",
        "##\n",
        "eta = reg01.params.log_Price\n",
        "##\n",
        "## The revenue elasticity is 1 + price elasticity\n",
        "##\n",
        "eta_rev = 1 + eta\n",
        "##\n",
        "## Put in DataFrame for display\n",
        "##\n",
        "df_elas = pd.DataFrame( [ eta, eta_rev ], columns = [ 'Elasticities'], \n",
        "    index = [ 'Price Elasticity', 'Revenue Elasticity' ] )\n",
        "df_elas.style.set_caption( 'Elasticity Summary').\\\n",
        "set_table_styles( tbl_styles ).\\\n",
        "format( '{:.1f}' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oduEGAsuGnW",
        "colab_type": "text"
      },
      "source": [
        "**Interpretation**\n",
        "\n",
        "Demand is highly elastic, but this pooled model does not allow us to check the Conjecture so we do not know how the elastcity varies by store location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDdT1hHOuGnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slide( '28' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkAYrsB2uGnY",
        "colab_type": "text"
      },
      "source": [
        "### Model Estimation II: Dummy Variable Model\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "Include a dummy variable for the store location: Urban or Suburban."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "4sanyBimuGnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## \n",
        "## OLS\n",
        "##\n",
        "## There are four steps for estimatng a model:\n",
        "##\n",
        "##   1. define a formula (i.e., the specific model to estimate)\n",
        "##   2. instantiate the model (i.e., specify it)\n",
        "##   3. fit the model\n",
        "##   4. summarize the fitted model\n",
        "##\n",
        "## ===> Step 1: Define a formula <===\n",
        "##\n",
        "## The formula uses a “~” to separate the left-hand side from the right-hand side\n",
        "## of a model and a “+” to add columns to the right-hand side.  A “-” sign (not \n",
        "## used here) can be used to remove columns from the right-hand side (e.g.,\n",
        "## remove or omit the constant term which is always included by default). \n",
        "##\n",
        "formula = 'log_Quantity ~ log_Price + log_Income + C(location) + log_Price*C(location)'\n",
        "##\n",
        "## ===> Step 2: Instantiate the OLS model <===\n",
        "##\n",
        "mod = smf.ols( formula, data = df )\n",
        "##\n",
        "## ===> Step 3: Fit the instantiated model <===\n",
        "##      Recommendation: number your fitted models\n",
        "##\n",
        "reg02 = mod.fit() \n",
        "##\n",
        "## ===> Step 4: Summarize the fitted model <===\n",
        "##\n",
        "print( reg02.summary() )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJOPl8k0uGnc",
        "colab_type": "text"
      },
      "source": [
        "#### Calculate the Price Elasticities: II\n",
        "\n",
        "[Back to Contents](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "9jQ_pP7XuGnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Retrieve estimated parameters\n",
        "##\n",
        "x = pd.DataFrame( reg02.params, columns = [ 'part_worth' ] )\n",
        "print( x )\n",
        "##\n",
        "## Calculate the price elasticities\n",
        "##\n",
        "eta_urban = sum( x.part_worth[ [ 2, 3 ] ] )\n",
        "eta_rural = x.part_worth[ 2 ]\n",
        "##\n",
        "## Calculate the revenue elasticities: 1 + price elasticity\n",
        "##\n",
        "eta_rev_urban = 1 + eta_urban\n",
        "eta_rev_rural = 1 + eta_rural\n",
        "##\n",
        "## Put in DataFrame for display\n",
        "##\n",
        "eta = [ [ eta_urban, eta_rev_urban ], [ eta_rural, eta_rev_rural ]]\n",
        "cols = pd.MultiIndex.from_product( [ [ 'Elasticity' ], [ 'Price', 'Revenue' ] ] )\n",
        "idx = [ 'Urban', 'Rural' ]\n",
        "df_elas = pd.DataFrame( eta, index = idx, columns = cols )\n",
        "df_elas.index.rename( 'Location', inplace = True )\n",
        "df_elas.style.set_caption( 'Elasticity Summary').\\\n",
        "set_table_styles( tbl_styles ).\\\n",
        "format( '{:.2f}' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1Qpk6HmuGnf",
        "colab_type": "text"
      },
      "source": [
        "**Interpretation**\n",
        "\n",
        "Urban stores are more elastic which supports the Conjecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLtpUC3nuGnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slide( '33' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVwpGZ_iuGnh",
        "colab_type": "text"
      },
      "source": [
        "### Model Estimation III: Multilevel Model\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "This is more complex -- it requires a separate course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTVs62XNuGni",
        "colab_type": "text"
      },
      "source": [
        "#### Data Structures\n",
        "\n",
        "There are two data structures: *Non-Nested* and *Nested* or *Multilevel*.\n",
        "\n",
        "**Definition**\n",
        "  *Non-nested Data*: The data in the population are at the same level.\n",
        "\n",
        ">**Example**\n",
        "\t\t> - All consumers in a random sample are the same.  Their behavior is driven solely by their traits -- and the prices they see.\n",
        "\n",
        "**Definition**\n",
        "  *Nested/Multilevel Data*: The data in the population are hierarchical.\n",
        "\n",
        ">**Examples**\n",
        "  > - Consumers shopping in a store.\n",
        "  > - Households in a marketing region."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzSdhn4YuGnj",
        "colab_type": "text"
      },
      "source": [
        "#### Marketing and Pricing Examples\n",
        "\n",
        "Examples of hierarchical structures are more common in marketing and pricing than thought:\n",
        "\n",
        "> - Segments\n",
        "> - Stores\n",
        "> - Marketing regions\n",
        "> - States\n",
        "> - Neighborhoods\n",
        "> - Organization membership\n",
        "> - Brand loyalty\n",
        "\n",
        "Many more could be listed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GyOVQIXuGnj",
        "colab_type": "text"
      },
      "source": [
        "#### Use of Multilevel Modeling\n",
        "\n",
        "A multilevel model allows a more detailed/finer analysis for the Conjecture.  Specifically: *What determines the elasticities*?\n",
        "\n",
        "This type of modeling is more complex -- so it is another course.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWXgqSAVuGnk",
        "colab_type": "text"
      },
      "source": [
        "## Summary and Wrap-Up\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "In this course, we covered:\n",
        "\n",
        "> - How to use a survey to collect data for pricing.\n",
        "> - How to estimate on survey-based model -- conjoint -- for pricing.\n",
        ">   - Conjoint is one member of a family of choice models.\n",
        "> - How to use transactions data for pricing.\n",
        ">   - There is a hierarchical structure to models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHWMZmsMuGnl",
        "colab_type": "text"
      },
      "source": [
        "## Contact Information\n",
        "\n",
        "[Back to Contents](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU1d1sgSuGnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slide( '41' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJafsOtnuGnp",
        "colab_type": "text"
      },
      "source": [
        "## Appendix: Extra Material\n",
        "\n",
        "[Back to Contents](#Contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYvuSZ6YuGnt",
        "colab_type": "text"
      },
      "source": [
        "### Conjoint Analysis\n",
        "\n",
        "[Back to Contents](#Contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2f516oYuGnt",
        "colab_type": "text"
      },
      "source": [
        "#### Display Attribute Importances\n",
        "\n",
        "[Back to Contents](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DcfWlMxuGnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Display a barchart of the importances\n",
        "##\n",
        "base = 'Base: All respondents'\n",
        "ax = sns.barplot( x = 'Importance', y = df_importances.index, data = df_importances,\n",
        "                order = df_importances.index )\n",
        "ax.set_title( 'Attribute Importances', fontsize = font_title )\n",
        "ax.set( ylabel = 'Attribute')\n",
        "tick_labels( 'x' )\n",
        "footer();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKeiPLGjuGnx",
        "colab_type": "text"
      },
      "source": [
        "#### Calculate Willingness to Pay\n",
        "\n",
        "[Back to Contents](#Contents)\n",
        "\n",
        "Willingness-to-Pay (*WTP*) is calculated using the formula:\n",
        "\n",
        "$𝑊𝑇𝑃 = \\dfrac{− \\beta_{𝐴𝑡𝑡𝑟𝑖𝑏𝑢𝑡𝑒~𝐿𝑒𝑣𝑒𝑙}}{\\beta_{𝑃𝑟𝑖𝑐𝑒}}$\n",
        "\n",
        "It is help/informative to know how mcu each consumer will pay extra for a difference level of each attribute.  This willingness-to-pay (*WTP*) for a level is relative to the base level in the effects coding.  See <a href=\"https://www.routledge.com/Pricing-Analytics-Models-and-Advanced-Quantitative-Techniques-for-Product/Paczkowski/p/book/9781138623934\" target=\"_parent\">here </a> for the formula derivation and a discussion of *WTP*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "wmR7vKIIuGnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Calculate WTP\n",
        "##\n",
        "beta_price = df_pw.query( 'att == \"Price\"' )[ 'Part-Worth' ][ 0 ]\n",
        "##\n",
        "lst_att = df_pw.att\n",
        "lst_level = df_pw.level\n",
        "lst_tups = list( zip( lst_att, lst_level ) )\n",
        "lst_tups = lst_tups[ : -1 ]\n",
        "n = len( lst_tups )\n",
        "##\n",
        "## Loop through part-worths\n",
        "##\n",
        "lst_wtp = []\n",
        "for i in range( n ):\n",
        "    att_what = lst_att[ i ]\n",
        "    level_what = lst_level[ i ]\n",
        "    beta = df_pw.query( ' att == @att_what and level == @level_what ' )[ 'Part-Worth' ][ 0 ]\n",
        "    wtp = ( -1 ) * beta/beta_price\n",
        "    lst_wtp.append( wtp )\n",
        "##\n",
        "## Create summary DataFrame\n",
        "##\n",
        "index = pd.MultiIndex.from_tuples( lst_tups, names=[ 'Attribute', 'Level' ] )    \n",
        "df_wtp = pd.DataFrame( lst_wtp, columns = [ 'WTP' ], index = index )\n",
        "df_wtp.style.set_caption( 'WTP Summary' ).format( {'WTP':format_dollar} )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTH8YuTWuGn1",
        "colab_type": "text"
      },
      "source": [
        "**Interpretation**\n",
        "\n",
        "The Distance measure has the largest *WTP*.  Consumers are willing to pay $0.19 more for the distance measure than the base Heart Monitoring measure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgGlqYtZuGn1",
        "colab_type": "text"
      },
      "source": [
        "### Transactions Analysis\n",
        "\n",
        "[Back to Contents](#Contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUendYlHuGn2",
        "colab_type": "text"
      },
      "source": [
        "#### Check Distributions\n",
        "\n",
        "[Back to Contents](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRbwgkCEuGn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Check distribution of sales by location\n",
        "##\n",
        "base = 'Base: All stores; n = ' + str( df.shape[ 0 ] )\n",
        "g = sns.FacetGrid( df, col = \"location\", margin_titles = True )\n",
        "g.map( sns.distplot, \"quantity\" )\n",
        "footer();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P02-uQiAuGoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Test for skewness for Suburban stores\n",
        "##\n",
        "x = df.query( 'location == \"Suburban\"' )\n",
        "sk = skewtest( x.quantity )\n",
        "print( 'Z-score: {z}\\np-Value: {p}'.format( z = round( sk[ 0 ], 3 ), p = round( sk[ 1 ], 4 ) ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzRBBvWmuGoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Test for skewness for Urban stores\n",
        "##\n",
        "x = df.query( 'location == \"Urban\"' )\n",
        "sk = skewtest( x.quantity )\n",
        "print( 'Z-score: {z}\\np-Value: {p}'.format( z = round( sk[ 0 ], 3 ), p = round( sk[ 1 ], 4 ) ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHQyzlAEuGoO",
        "colab_type": "text"
      },
      "source": [
        "#### Sales and Price Relationship\n",
        "\n",
        "[Back to Contents](#Contents)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "OGCN_sYEuGoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Graph relationship of sales by price for locations\n",
        "##\n",
        "base = 'Base: All stores; n = ' + str( df.shape[ 0 ] )\n",
        "g = sns.FacetGrid( df, col = \"location\", margin_titles = True )\n",
        "g.map( sns.lineplot, 'price', 'quantity' );"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0x7lcX9uGoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##\n",
        "## Graph relationship of sales by price for locations\n",
        "##\n",
        "base = 'Base: All stores; n = ' + str( df.shape[ 0 ] )\n",
        "ax = sns.scatterplot( y = 'quantity', x = 'price', hue = 'location', data = df )\n",
        "ax.set_title( 'Sales by Store Location', fontsize = font_title )\n",
        "ax.set( ylabel = 'Quantity', xlabel = 'Sales' )\n",
        "footer();"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}